{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models and predictions\n",
    "\n",
    "Today, we will explore the fuel efficiency dataset some more to introduce one of the most important concepts in machine learning: the _bias-variance tradeoff_.  We'll also introduce a few new scikit-learn features while we're at it.\n",
    "\n",
    "Let's start by pulling in a few imports and loading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/auto_mpg.csv')\n",
    "#df = pd.read_csv('/blue/zoo4926/share/Jupyter_Content/data/auto_mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab all of the columns except for `'name'` and `'mpg'` and try building a linear regression model with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** We can use our model's `score()` method to get the value of $R^2$ for our model. Write code to calculate the overall loss, using mean squared error as the loss function ($MSE$).  Hint 1: you can use the model's `predict()` method (e.g., `model.predict(x)`) to get the estimated $y$ values.  Hint 2:\n",
    "\n",
    "$$ MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y_i})^2 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that earlier, we discovered we could improve the simple regression model, which used only $hp$ as a predictor variable, by adding $hp^2$ as a second predictor.  What if we use the same idea on all of our predictor variables for our current model?\n",
    "\n",
    "We can use scikit-learn's `PolynomialFeatures` to easily implement this.  For example, if we create a `PolynomialFeatures` object with the code `PolynomialFeatures(degree=2)`, we can easily create a dataset that includes the square of every variable by calling the `fit_transform()` method of `PolynomialFeatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the output of `fit_transform()` to fit our linear model, but we can make things even easier by using a scikit-learn [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), which can automatically transform our input data using `PolynomialFeatures` and then use the transformed data to fit a `LinearRegression` model.\n",
    "\n",
    "To do this, we call `Pipeline()` and pass in a list of the objects we want included in the modeling pipeline.  Each pipeline component object needs to be placed in a tuple that includes a name for the pipeline step; e.g., `('name', pipeline_component)`.  After we've created our `Pipeline`, we can use it just like any model object in scikit-learn.  For example, we can call `fit()`, `predict()`, `score()`, and so on.\n",
    "\n",
    "Note that, when using `LinearRegression` with `PolynomialFeatures`, you need to instantiate your `LinearRegression` object with the argument `fit_intercept=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did everything correctly, we should have achieved a very impressive model fit.  But how good is our model, _really_?  Let's explore that next (after a brief thought exercise).\n",
    "\n",
    "For this, we'll use scikit-learn's very handy [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which lets us randomly break a dataset in two by specifying a value in the range $[0-1]$ for the `test_size` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
